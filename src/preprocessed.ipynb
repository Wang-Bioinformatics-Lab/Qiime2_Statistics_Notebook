{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from gnpsdata import taskresult\n",
    "import os\n",
    "from gnpsdata import workflow_fbmn\n",
    "import pandas as pd\n",
    "from qiime2 import Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"cf6e14abf5604f47b28b467a513d3532\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downloading raw data from GNPS\n",
    "def download_graphml(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"gnps_molecular_network_graphml/\", output_file)\n",
    "\n",
    "def get_graphml_network(task):\n",
    "    taskresult.download_task_resultfile(task, \"gnps_molecular_network_graphml/\", \"temp.graphml\")\n",
    "\n",
    "    G = nx.read_graphml(\"temp.graphml\")\n",
    "\n",
    "    return G\n",
    "\n",
    "def download_quantification(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"quantification_table/\", output_file)\n",
    "\n",
    "def download_metadata(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"metadata_merged/\", output_file)\n",
    "\n",
    "def download_mgf(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"spectra_reformatted/\", output_file)\n",
    "    \n",
    "# Qiime2 Data\n",
    "def download_qiime2(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"qiime2_output/qiime2_table.qza\", output_file)\n",
    "\n",
    "def download_qiime2_manifest(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"qiime2_output/qiime2_manifest.tsv\", output_file)\n",
    "\n",
    "def download_qiime2_metadata(task, output_file):\n",
    "    taskresult.download_task_resultfile(task, \"qiime2_output/qiime2_metadata.tsv\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download quantification and manifest\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "download_quantification(task, \"../data/quant.csv\")\n",
    "download_qiime2_manifest(task, \"../data/manifest.csv\")\n",
    "# Downloading metadata\n",
    "workflow_fbmn.download_metadata(task, \"../data/unprocessed_metadata.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Metadata and Manifest Column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read metadata file\n",
    "metadata = pd.read_csv(\"../data/unprocessed_metadata.tsv\", sep = \"\\t\", index_col=False)\n",
    "#rename 1st column to \"#sample id\n",
    "metadata = metadata.rename(columns={\"filename\":\"sample id\"})\n",
    "#convert back to .tsv\n",
    "metadata.to_csv('../data/metadata.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "import skbio # Don't import on Windows!!\n",
    "from ipyfilechooser import FileChooser\n",
    "from ipywidgets import interact\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings for cleaner output, comment out for debugging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blank Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder with data files\n",
    "result_dir = \"../data/\"\n",
    "#Read quant.csv and metadata .tsv\n",
    "ft = pd.read_csv(\"../data/quant.csv\")\n",
    "md = pd.read_csv(\"../data/metadata.tsv\", sep = \"\\t\").set_index(\"sample id\")\n",
    "\n",
    "# When cutoff is low, more noise (or background) detected; With higher cutoff, less background detected, thus more features observed\n",
    "cutoff = 0.1\n",
    "\n",
    "def inside_levels(df):\n",
    "    # get all the columns (equals all attributes) -> will be number of rows\n",
    "    levels = []\n",
    "    types = []\n",
    "    count = []\n",
    "    for col in df.columns:\n",
    "        types.append(type(df[col][0]))\n",
    "        levels.append(sorted(set(df[col].dropna())))\n",
    "        tmp = df[col].value_counts()\n",
    "        count.append([tmp[levels[-1][i]] for i in range(len(levels[-1]))])\n",
    "    return pd.DataFrame({\"ATTRIBUTES\": df.columns, \"LEVELS\": levels, \"COUNT\":count, \"TYPES\": types}, index=range(1, len(levels)+1))\n",
    "new_md = md.copy() #storing the files under different names to preserve the original files\n",
    "# remove the (front & tail) spaces, if any present, from the rownames of md\n",
    "new_md.index = [name.strip() for name in md.index]\n",
    "# for each col in new_md\n",
    "# 1) removing the spaces (if any)\n",
    "# 2) replace the spaces (in the middle) to underscore\n",
    "# 3) converting them all to UPPERCASE\n",
    "for col in new_md.columns:\n",
    "    if new_md[col].dtype == str:\n",
    "        new_md[col] = [item.strip().replace(\" \", \"_\").upper() for item in new_md[col]]\n",
    "\n",
    "new_ft = ft.copy() #storing the files under different names to preserve the original files\n",
    "# changing the index in feature table to contain m/z and RT information\n",
    "new_ft.index = [f\"{id}_{round(mz, 3)}_{round(rt, 3)}\" for id, mz, rt in zip(ft[\"row ID\"], ft[\"row m/z\"], ft[\"row retention time\"])]\n",
    "new_ft.index.name = \"CustomIndex\"\n",
    "# drop all columns that are not mzML or mzXML file names\n",
    "new_ft.drop(columns=[col for col in new_ft.columns if \".mz\" not in col], inplace=True)\n",
    "# remove \" Peak area\" from column names\n",
    "new_ft.rename(columns={col: col.replace(\" Peak area\", \"\").strip() for col in new_ft.columns}, inplace=True)\n",
    "\n",
    "if sorted(new_ft.columns) != sorted(new_md.index):\n",
    "    # print the md rows / ft column which are not in ft columns / md rows and remove them\n",
    "    ft_cols_not_in_md = [col for col in new_ft.columns if col not in new_md.index]\n",
    "    new_ft.drop(columns=ft_cols_not_in_md, inplace=True)\n",
    "    md_rows_not_in_ft = [row for row in new_md.index if row not in new_ft.columns]\n",
    "    new_md.drop(md_rows_not_in_ft, inplace=True)\n",
    "\n",
    "new_ft = new_ft.reindex(sorted(new_ft.columns), axis=1) #ordering the ft by its column names\n",
    "new_md.sort_index(inplace=True) #ordering the md by its row names\n",
    "list(new_ft.columns) == list(new_md.index)\n",
    "data = new_md\n",
    "condition = 2\n",
    "df = pd.DataFrame({\"LEVELS\": inside_levels(data).iloc[condition-1][\"LEVELS\"]})\n",
    "df.index = [*range(1, len(df)+1)]\n",
    "#Among the shown levels of an attribute, select the ones to keep\n",
    "blank_id = 1\n",
    "#Splitting the data into blanks and samples based on the metadata\n",
    "md_blank = data[data[inside_levels(data)['ATTRIBUTES'][condition]] == df['LEVELS'][blank_id]]\n",
    "blank = new_ft[list(md_blank.index)]\n",
    "md_samples = data[data[inside_levels(data)['ATTRIBUTES'][condition]] != df['LEVELS'][blank_id]]\n",
    "samples = new_ft[list(md_samples.index)]\n",
    "\n",
    "blank_removal = samples.copy()\n",
    "\n",
    "# Getting mean for every feature in blank and Samples\n",
    "avg_blank = blank.mean(axis=1, skipna=False) # set skipna = False do not exclude NA/null values when computing the result.\n",
    "avg_samples = samples.mean(axis=1, skipna=False)\n",
    "\n",
    "# Getting the ratio of blank vs samples\n",
    "ratio_blank_samples = (avg_blank+1)/(avg_samples+1)\n",
    "\n",
    "# Create an array with boolean values: True (is a real feature, ratio<cutoff) / False (is a blank, background, noise feature, ratio>cutoff)\n",
    "is_real_feature = (ratio_blank_samples<cutoff)\n",
    "blank_removal = samples[is_real_feature.values]\n",
    "imputation_samples = blank_removal.copy()\n",
    "\n",
    "# save to file\n",
    "entry_id = []\n",
    "entry_mz = []\n",
    "entry_time = []\n",
    "for entryCol in blank_removal.index:\n",
    "    entry = entryCol.split(\"_\")\n",
    "    entry_id.append(entry[0])\n",
    "    entry_mz.append(entry[1])\n",
    "    entry_time.append(entry[2])\n",
    "blank_removal.insert(0,\"#OTU ID\",entry_id,True)\n",
    "# blank_removal.insert(1,\"sample_name\",entry_mz,True)\n",
    "# blank_removal.insert(2,\"abundance\",entry_time,True)\n",
    "blank_removal.to_csv(os.path.join(result_dir, \"Blanks_Removed.tsv\"), sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, bins_label, a = [-1, 0, 1, 10], ['-1','0', \"1\", \"10\"], 2\n",
    "\n",
    "while a<=10:\n",
    "    bins_label.append(np.format_float_scientific(10**a))\n",
    "    bins.append(10**a)\n",
    "    a+=1\n",
    "\n",
    "freq_table = pd.DataFrame(bins_label)\n",
    "frequency = pd.DataFrame(np.array(np.unique(np.digitize(imputation_samples.to_numpy(), bins, right=True), return_counts=True)).T).set_index(0)\n",
    "freq_table = pd.concat([freq_table,frequency], axis=1).fillna(0).drop(0)\n",
    "freq_table.columns = ['intensity', 'Frequency']\n",
    "freq_table['Log(Frequency)'] = np.log(freq_table['Frequency']+1)\n",
    "\n",
    "# get the lowest intensity (that is not zero) as a cutoff LOD value\n",
    "cutoff_LOD = round(imputation_samples.replace(0, np.nan).min(numeric_only=True).min())\n",
    "\n",
    "imputed = imputation_samples.copy()\n",
    "entry_id = []\n",
    "entry_mz = []\n",
    "entry_time = []\n",
    "for entryCol in imputed.index:\n",
    "    entry = entryCol.split(\"_\")\n",
    "    entry_id.append(entry[0])\n",
    "    entry_mz.append(entry[1])\n",
    "    entry_time.append(entry[2])\n",
    "imputed.insert(0,\"#OTU ID\",entry_id,True)\n",
    "# imputed.insert(1,\"sample_name\",entry_mz,True)\n",
    "# imputed.insert(2,\"abundance\",entry_time,True)\n",
    "imputed = imputed.apply(lambda x: [np.random.randint(0, cutoff_LOD) if v == 0 else v for v in x])\n",
    "# save to file\n",
    "imputed.to_csv(os.path.join(result_dir, \"Imputed_QuantTable.tsv\"), sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = imputation_samples.copy()\n",
    "# Dividing each element of a particular column with its column sum\n",
    "normalized = normalized.apply(lambda x: x/np.sum(x), axis=0)\n",
    "normalized_samples = normalized.copy()\n",
    "entry_id = []\n",
    "entry_mz = []\n",
    "entry_time = []\n",
    "for entryCol in normalized_samples.index:\n",
    "    entry = entryCol.split(\"_\")\n",
    "    entry_id.append(entry[0])\n",
    "    entry_mz.append(entry[1])\n",
    "    entry_time.append(entry[2])\n",
    "normalized_samples.insert(0,\"#OTU ID\",entry_id,True)\n",
    "# normalized_samples.insert(1,\"sample_name\",entry_mz,True)\n",
    "# normalized_samples.insert(2,\"abundance\",entry_time,True)\n",
    "normalized_samples.to_csv(os.path.join(result_dir, \"Normalised_Quant_table.tsv\"), sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the imputed table before scaling\n",
    "transposed = imputation_samples.T\n",
    "# put the rows in the feature table and metadata in the same order\n",
    "transposed.sort_index(inplace=True)\n",
    "md_samples.sort_index(inplace=True)\n",
    "\n",
    "if (md_samples.index == transposed.index).all():\n",
    "    pass\n",
    "else:\n",
    "    print(\"WARNING: Sample names in feature and metadata table are NOT the same!\")\n",
    "transposed.to_csv(os.path.join(result_dir, \"Imputed_QuantTable_transposed.csv\"))\n",
    "\n",
    "# scale filtered data\n",
    "scaled = pd.DataFrame(StandardScaler().fit_transform(transposed), index=transposed.index, columns=transposed.columns)\n",
    "scaled = scaled.T\n",
    "entry_id = []\n",
    "entry_mz = []\n",
    "entry_time = []\n",
    "for entryCol in scaled.index:\n",
    "    entry = entryCol.split(\"_\")\n",
    "    entry_id.append(entry[0])\n",
    "    entry_mz.append(entry[1])\n",
    "    entry_time.append(entry[2])\n",
    "scaled.insert(0,\"#OTU ID\",entry_id,True)\n",
    "# scaled.insert(1,\"sample_name\",entry_mz,True)\n",
    "# scaled.insert(2,\"abundance\",entry_time,True)\n",
    "scaled.to_csv(os.path.join(result_dir, \"Imputed_Scaled_QuantTable.tsv\"), sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Into Qiime2\n",
    "## Convert .tsv to .biom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! biom convert \\\n",
    "  -i ../data/Normalised_Quant_table.tsv \\\n",
    "  -o ../data/quant.biom --to-hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported ../data/quant.biom as BIOMV210Format to ../data/qiime_table.qza\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime tools import \\\n",
    "  --input-path ../data/quant.biom \\\n",
    "  --type 'FeatureTable[Frequency]' \\\n",
    "  --input-format BIOMV210Format \\\n",
    "  --output-path ../data/qiime_table.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Metadata and Normalized Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CustomIndex</th>\n",
       "      <th>2127_151.096_0.986</th>\n",
       "      <th>86368_151.098_11.096</th>\n",
       "      <th>90458_151.098_12.344</th>\n",
       "      <th>88889_151.098_11.826</th>\n",
       "      <th>87841_151.098_11.55</th>\n",
       "      <th>92531_152.947_13.15</th>\n",
       "      <th>92590_152.947_13.511</th>\n",
       "      <th>1531_152.947_0.753</th>\n",
       "      <th>39078_153.091_5.457</th>\n",
       "      <th>22910_153.091_4.085</th>\n",
       "      <th>...</th>\n",
       "      <th>88116_1444.398_11.482</th>\n",
       "      <th>89487_1444.398_12.017</th>\n",
       "      <th>86967_1444.398_11.216</th>\n",
       "      <th>90591_1444.399_12.387</th>\n",
       "      <th>91218_1444.399_12.614</th>\n",
       "      <th>92162_1444.399_12.973</th>\n",
       "      <th>88518_1444.399_11.718</th>\n",
       "      <th>88057_1445.398_11.541</th>\n",
       "      <th>89348_1445.398_11.988</th>\n",
       "      <th>91876_1445.399_12.863</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#OTU ID</th>\n",
       "      <td>2127</td>\n",
       "      <td>86368</td>\n",
       "      <td>90458</td>\n",
       "      <td>88889</td>\n",
       "      <td>87841</td>\n",
       "      <td>92531</td>\n",
       "      <td>92590</td>\n",
       "      <td>1531</td>\n",
       "      <td>39078</td>\n",
       "      <td>22910</td>\n",
       "      <td>...</td>\n",
       "      <td>88116</td>\n",
       "      <td>89487</td>\n",
       "      <td>86967</td>\n",
       "      <td>90591</td>\n",
       "      <td>91218</td>\n",
       "      <td>92162</td>\n",
       "      <td>88518</td>\n",
       "      <td>88057</td>\n",
       "      <td>89348</td>\n",
       "      <td>91876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_10_a.mzXML</th>\n",
       "      <td>-0.36621</td>\n",
       "      <td>-0.146293</td>\n",
       "      <td>-0.672484</td>\n",
       "      <td>-0.57864</td>\n",
       "      <td>-0.506848</td>\n",
       "      <td>-1.059521</td>\n",
       "      <td>-0.730349</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>-0.843086</td>\n",
       "      <td>-0.402539</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508335</td>\n",
       "      <td>3.052098</td>\n",
       "      <td>0.572418</td>\n",
       "      <td>0.252387</td>\n",
       "      <td>2.482082</td>\n",
       "      <td>-0.366943</td>\n",
       "      <td>1.031651</td>\n",
       "      <td>2.338755</td>\n",
       "      <td>0.588116</td>\n",
       "      <td>1.222231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_10_b.mzXML</th>\n",
       "      <td>0.137203</td>\n",
       "      <td>-0.146293</td>\n",
       "      <td>-0.672484</td>\n",
       "      <td>-0.57864</td>\n",
       "      <td>-0.506848</td>\n",
       "      <td>-0.470587</td>\n",
       "      <td>-0.563991</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>-0.734772</td>\n",
       "      <td>-0.389619</td>\n",
       "      <td>...</td>\n",
       "      <td>4.49691</td>\n",
       "      <td>1.195304</td>\n",
       "      <td>0.879027</td>\n",
       "      <td>3.887736</td>\n",
       "      <td>0.67784</td>\n",
       "      <td>1.303225</td>\n",
       "      <td>2.430627</td>\n",
       "      <td>1.951121</td>\n",
       "      <td>-0.37495</td>\n",
       "      <td>5.024339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_11_a.mzXML</th>\n",
       "      <td>-0.584305</td>\n",
       "      <td>-0.146293</td>\n",
       "      <td>-0.672484</td>\n",
       "      <td>-0.57864</td>\n",
       "      <td>-0.506848</td>\n",
       "      <td>-1.059521</td>\n",
       "      <td>-0.716952</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>-0.952998</td>\n",
       "      <td>-0.368446</td>\n",
       "      <td>...</td>\n",
       "      <td>3.517718</td>\n",
       "      <td>0.932056</td>\n",
       "      <td>0.599707</td>\n",
       "      <td>0.296781</td>\n",
       "      <td>0.453892</td>\n",
       "      <td>-0.366943</td>\n",
       "      <td>4.161232</td>\n",
       "      <td>-0.421199</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.90449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_11_b.mzXML</th>\n",
       "      <td>-0.584305</td>\n",
       "      <td>-0.146293</td>\n",
       "      <td>-0.672484</td>\n",
       "      <td>-0.57864</td>\n",
       "      <td>-0.506848</td>\n",
       "      <td>-0.142732</td>\n",
       "      <td>-0.338595</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>-0.952998</td>\n",
       "      <td>-0.359367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044128</td>\n",
       "      <td>1.422047</td>\n",
       "      <td>1.617739</td>\n",
       "      <td>1.573123</td>\n",
       "      <td>2.242894</td>\n",
       "      <td>1.151043</td>\n",
       "      <td>2.375342</td>\n",
       "      <td>1.69254</td>\n",
       "      <td>2.869942</td>\n",
       "      <td>0.976246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3965 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CustomIndex           2127_151.096_0.986 86368_151.098_11.096  \\\n",
       "#OTU ID                             2127                86368   \n",
       "SD_01-2018_10_a.mzXML           -0.36621            -0.146293   \n",
       "SD_01-2018_10_b.mzXML           0.137203            -0.146293   \n",
       "SD_01-2018_11_a.mzXML          -0.584305            -0.146293   \n",
       "SD_01-2018_11_b.mzXML          -0.584305            -0.146293   \n",
       "\n",
       "CustomIndex           90458_151.098_12.344 88889_151.098_11.826  \\\n",
       "#OTU ID                              90458                88889   \n",
       "SD_01-2018_10_a.mzXML            -0.672484             -0.57864   \n",
       "SD_01-2018_10_b.mzXML            -0.672484             -0.57864   \n",
       "SD_01-2018_11_a.mzXML            -0.672484             -0.57864   \n",
       "SD_01-2018_11_b.mzXML            -0.672484             -0.57864   \n",
       "\n",
       "CustomIndex           87841_151.098_11.55 92531_152.947_13.15  \\\n",
       "#OTU ID                             87841               92531   \n",
       "SD_01-2018_10_a.mzXML           -0.506848           -1.059521   \n",
       "SD_01-2018_10_b.mzXML           -0.506848           -0.470587   \n",
       "SD_01-2018_11_a.mzXML           -0.506848           -1.059521   \n",
       "SD_01-2018_11_b.mzXML           -0.506848           -0.142732   \n",
       "\n",
       "CustomIndex           92590_152.947_13.511 1531_152.947_0.753  \\\n",
       "#OTU ID                              92590               1531   \n",
       "SD_01-2018_10_a.mzXML            -0.730349          -0.268576   \n",
       "SD_01-2018_10_b.mzXML            -0.563991          -0.268576   \n",
       "SD_01-2018_11_a.mzXML            -0.716952          -0.268576   \n",
       "SD_01-2018_11_b.mzXML            -0.338595          -0.268576   \n",
       "\n",
       "CustomIndex           39078_153.091_5.457 22910_153.091_4.085  ...  \\\n",
       "#OTU ID                             39078               22910  ...   \n",
       "SD_01-2018_10_a.mzXML           -0.843086           -0.402539  ...   \n",
       "SD_01-2018_10_b.mzXML           -0.734772           -0.389619  ...   \n",
       "SD_01-2018_11_a.mzXML           -0.952998           -0.368446  ...   \n",
       "SD_01-2018_11_b.mzXML           -0.952998           -0.359367  ...   \n",
       "\n",
       "CustomIndex           88116_1444.398_11.482 89487_1444.398_12.017  \\\n",
       "#OTU ID                               88116                 89487   \n",
       "SD_01-2018_10_a.mzXML              1.508335              3.052098   \n",
       "SD_01-2018_10_b.mzXML               4.49691              1.195304   \n",
       "SD_01-2018_11_a.mzXML              3.517718              0.932056   \n",
       "SD_01-2018_11_b.mzXML              1.044128              1.422047   \n",
       "\n",
       "CustomIndex           86967_1444.398_11.216 90591_1444.399_12.387  \\\n",
       "#OTU ID                               86967                 90591   \n",
       "SD_01-2018_10_a.mzXML              0.572418              0.252387   \n",
       "SD_01-2018_10_b.mzXML              0.879027              3.887736   \n",
       "SD_01-2018_11_a.mzXML              0.599707              0.296781   \n",
       "SD_01-2018_11_b.mzXML              1.617739              1.573123   \n",
       "\n",
       "CustomIndex           91218_1444.399_12.614 92162_1444.399_12.973  \\\n",
       "#OTU ID                               91218                 92162   \n",
       "SD_01-2018_10_a.mzXML              2.482082             -0.366943   \n",
       "SD_01-2018_10_b.mzXML               0.67784              1.303225   \n",
       "SD_01-2018_11_a.mzXML              0.453892             -0.366943   \n",
       "SD_01-2018_11_b.mzXML              2.242894              1.151043   \n",
       "\n",
       "CustomIndex           88518_1444.399_11.718 88057_1445.398_11.541  \\\n",
       "#OTU ID                               88518                 88057   \n",
       "SD_01-2018_10_a.mzXML              1.031651              2.338755   \n",
       "SD_01-2018_10_b.mzXML              2.430627              1.951121   \n",
       "SD_01-2018_11_a.mzXML              4.161232             -0.421199   \n",
       "SD_01-2018_11_b.mzXML              2.375342               1.69254   \n",
       "\n",
       "CustomIndex           89348_1445.398_11.988 91876_1445.399_12.863  \n",
       "#OTU ID                               89348                 91876  \n",
       "SD_01-2018_10_a.mzXML              0.588116              1.222231  \n",
       "SD_01-2018_10_b.mzXML              -0.37495              5.024339  \n",
       "SD_01-2018_11_a.mzXML              0.763702               0.90449  \n",
       "SD_01-2018_11_b.mzXML              2.869942              0.976246  \n",
       "\n",
       "[5 rows x 3965 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATTRIBUTE_Sample-Type</th>\n",
       "      <th>ATTRIBUTE_Batch</th>\n",
       "      <th>ATTRIBUTE_Month</th>\n",
       "      <th>ATTRIBUTE_Year</th>\n",
       "      <th>ATTRIBUTE_Sample_Location</th>\n",
       "      <th>ATTRIBUTE_Replicate</th>\n",
       "      <th>ATTRIBUTE_Spot</th>\n",
       "      <th>ATTRIBUTE_Latitude</th>\n",
       "      <th>ATTRIBUTE_Longitude</th>\n",
       "      <th>ATTRIBUTE_Sample_Area</th>\n",
       "      <th>ATTRIBUTE_Spot_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_10_a.mzXML</th>\n",
       "      <td>Sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "      <td>32.86261</td>\n",
       "      <td>-117.26042</td>\n",
       "      <td>SIO_La_Jolla_Shores</td>\n",
       "      <td>SIO_South_Pier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_10_b.mzXML</th>\n",
       "      <td>Sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "      <td>10</td>\n",
       "      <td>32.86261</td>\n",
       "      <td>-117.26042</td>\n",
       "      <td>SIO_La_Jolla_Shores</td>\n",
       "      <td>SIO_South_Pier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_11_a.mzXML</th>\n",
       "      <td>Sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "      <td>32.85601</td>\n",
       "      <td>-117.26253</td>\n",
       "      <td>SIO_La_Jolla_Shores</td>\n",
       "      <td>La_Jolla_Shores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_11_b.mzXML</th>\n",
       "      <td>Sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>b</td>\n",
       "      <td>11</td>\n",
       "      <td>32.85601</td>\n",
       "      <td>-117.26253</td>\n",
       "      <td>SIO_La_Jolla_Shores</td>\n",
       "      <td>La_Jolla_Shores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_01-2018_12_a.mzXML</th>\n",
       "      <td>Sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>a</td>\n",
       "      <td>12</td>\n",
       "      <td>32.85161</td>\n",
       "      <td>-117.26965</td>\n",
       "      <td>La_Jolla_Cove</td>\n",
       "      <td>Cove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ATTRIBUTE_Sample-Type  ATTRIBUTE_Batch ATTRIBUTE_Month  \\\n",
       "SD_01-2018_10_a.mzXML                Sample                2             Jan   \n",
       "SD_01-2018_10_b.mzXML                Sample                2             Jan   \n",
       "SD_01-2018_11_a.mzXML                Sample                2             Jan   \n",
       "SD_01-2018_11_b.mzXML                Sample                2             Jan   \n",
       "SD_01-2018_12_a.mzXML                Sample                2             Jan   \n",
       "\n",
       "                       ATTRIBUTE_Year  ATTRIBUTE_Sample_Location  \\\n",
       "SD_01-2018_10_a.mzXML            2018                         10   \n",
       "SD_01-2018_10_b.mzXML            2018                         10   \n",
       "SD_01-2018_11_a.mzXML            2018                         11   \n",
       "SD_01-2018_11_b.mzXML            2018                         11   \n",
       "SD_01-2018_12_a.mzXML            2018                         12   \n",
       "\n",
       "                      ATTRIBUTE_Replicate  ATTRIBUTE_Spot  ATTRIBUTE_Latitude  \\\n",
       "SD_01-2018_10_a.mzXML                   a              10            32.86261   \n",
       "SD_01-2018_10_b.mzXML                   b              10            32.86261   \n",
       "SD_01-2018_11_a.mzXML                   a              11            32.85601   \n",
       "SD_01-2018_11_b.mzXML                   b              11            32.85601   \n",
       "SD_01-2018_12_a.mzXML                   a              12            32.85161   \n",
       "\n",
       "                       ATTRIBUTE_Longitude ATTRIBUTE_Sample_Area  \\\n",
       "SD_01-2018_10_a.mzXML           -117.26042   SIO_La_Jolla_Shores   \n",
       "SD_01-2018_10_b.mzXML           -117.26042   SIO_La_Jolla_Shores   \n",
       "SD_01-2018_11_a.mzXML           -117.26253   SIO_La_Jolla_Shores   \n",
       "SD_01-2018_11_b.mzXML           -117.26253   SIO_La_Jolla_Shores   \n",
       "SD_01-2018_12_a.mzXML           -117.26965         La_Jolla_Cove   \n",
       "\n",
       "                      ATTRIBUTE_Spot_Name  \n",
       "SD_01-2018_10_a.mzXML      SIO_South_Pier  \n",
       "SD_01-2018_10_b.mzXML      SIO_South_Pier  \n",
       "SD_01-2018_11_a.mzXML     La_Jolla_Shores  \n",
       "SD_01-2018_11_b.mzXML     La_Jolla_Shores  \n",
       "SD_01-2018_12_a.mzXML                Cove  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transposed_scaled = scaled.transpose()\n",
    "display(transposed_scaled.head())\n",
    "display(md_samples.head())\n",
    "Data = pd.merge(md_samples, transposed_scaled, left_index=True, right_index=True, how=\"inner\")\n",
    "Data.index.name = 'sample_name'\n",
    "Data.to_csv(os.path.join(result_dir, \"merged_metadata.tsv\"), sep = \"\\t\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: ../data/metadata.qzv\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime longitudinal anova \\\n",
    "  --m-metadata-file ../data/metadata.tsv \\\n",
    "  --p-formula \"ATTRIBUTE_Sample_Location~ATTRIBUTE_Sample_Area+ATTRIBUTE_Latitude\" \\\n",
    "  --p-sstype 'I' \\\n",
    "  --o-visualization ../data/metadata.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><img onload=\"(function(div, url){\n",
       "if (typeof require !== 'undefined') {\n",
       "    var baseURL = require.toUrl('').split('/').slice(0, -2).join('/');\n",
       "} else {\n",
       "    var baseURL = JSON.parse(\n",
       "        document.getElementById('jupyter-config-data').innerHTML\n",
       "    ).baseUrl.slice(0, -1);\n",
       "}\n",
       "url = baseURL + url;\n",
       "fetch(url).then(function(res) {\n",
       "    if (res.status === 404) {\n",
       "        div.innerHTML = 'Install QIIME 2 Jupyter extension with:<br />' +\n",
       "                        '<code>jupyter serverextension enable --py qiime2' +\n",
       "                        ' --sys-prefix</code><br />then restart your server.' +\n",
       "                        '<br /><br />(Interactive output not available on ' +\n",
       "                        'static notebook viewer services like nbviewer.)';\n",
       "    } else if (res.status === 409) {\n",
       "        div.innerHTML = 'Visualization no longer in scope. Re-run this cell' +\n",
       "                        ' to see the visualization.';\n",
       "    } else if (res.ok) {\n",
       "        url = res.url;\n",
       "        div.innerHTML = '<iframe src=\\'' + url + '\\' style=\\'' +\n",
       "                        'width: 100%; height: 700px; border: 0;\\'>' +\n",
       "                        '</iframe><hr />Open in a: <a href=\\'' + url + '\\'' +\n",
       "                        ' target=\\'_blank\\'>new window</a>'\n",
       "    } else {\n",
       "        div.innerHTML = 'Something has gone wrong. Check notebook server for' +\n",
       "                        ' errors.';\n",
       "    }\n",
       "});\n",
       "})(this.parentElement, '/qiime2/redirect?location=/tmp/qiime2/root/data/80ab619a-4f0f-432b-b950-4f8ab402815e')\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" /></div>"
      ],
      "text/plain": [
       "<visualization: Visualization uuid: 80ab619a-4f0f-432b-b950-4f8ab402815e>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Visualization.load('../data/metadata.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization\n",
    "Qiime2 visualizations do not work in headless environments, we can view them at https://view.qiime2.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Coordinate Analysis (PCoA) & Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved DistanceMatrix to: ../data/distance_matrix.qza\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime diversity beta \\\n",
    "  --i-table ../data/qiime_table.qza \\\n",
    "  --p-metric canberra_adkins \\\n",
    "  --o-distance-matrix ../data/distance_matrix.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved PCoAResults to: ../data/pcoa.qza\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime diversity pcoa \\\n",
    "  --i-distance-matrix ../data/distance_matrix.qza \\\n",
    "  --o-pcoa ../data/pcoa.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emperor plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: ../data/emperor_plot.qzv\u001b[0m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime emperor plot \\\n",
    "  --i-pcoa ../data/pcoa.qza \\\n",
    "  --m-metadata-file ../data/metadata.tsv \\\n",
    "  --o-visualization ../data/emperor_plot \\\n",
    "  --p-ignore-missing-samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><img onload=\"(function(div, url){\n",
       "if (typeof require !== 'undefined') {\n",
       "    var baseURL = require.toUrl('').split('/').slice(0, -2).join('/');\n",
       "} else {\n",
       "    var baseURL = JSON.parse(\n",
       "        document.getElementById('jupyter-config-data').innerHTML\n",
       "    ).baseUrl.slice(0, -1);\n",
       "}\n",
       "url = baseURL + url;\n",
       "fetch(url).then(function(res) {\n",
       "    if (res.status === 404) {\n",
       "        div.innerHTML = 'Install QIIME 2 Jupyter extension with:<br />' +\n",
       "                        '<code>jupyter serverextension enable --py qiime2' +\n",
       "                        ' --sys-prefix</code><br />then restart your server.' +\n",
       "                        '<br /><br />(Interactive output not available on ' +\n",
       "                        'static notebook viewer services like nbviewer.)';\n",
       "    } else if (res.status === 409) {\n",
       "        div.innerHTML = 'Visualization no longer in scope. Re-run this cell' +\n",
       "                        ' to see the visualization.';\n",
       "    } else if (res.ok) {\n",
       "        url = res.url;\n",
       "        div.innerHTML = '<iframe src=\\'' + url + '\\' style=\\'' +\n",
       "                        'width: 100%; height: 700px; border: 0;\\'>' +\n",
       "                        '</iframe><hr />Open in a: <a href=\\'' + url + '\\'' +\n",
       "                        ' target=\\'_blank\\'>new window</a>'\n",
       "    } else {\n",
       "        div.innerHTML = 'Something has gone wrong. Check notebook server for' +\n",
       "                        ' errors.';\n",
       "    }\n",
       "});\n",
       "})(this.parentElement, '/qiime2/redirect?location=/tmp/qiime2/root/data/5b617d68-4f32-4fc4-9f85-d920d968a666')\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" /></div>"
      ],
      "text/plain": [
       "<visualization: Visualization uuid: 5b617d68-4f32-4fc4-9f85-d920d968a666>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Visualization.load('../data/emperor_plot.qzv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \u001b[94mqiime sample-classifier classify-samples\u001b[0m [OPTIONS]\r\n",
      "\r\n",
      "  Predicts a categorical sample metadata column using a supervised learning\r\n",
      "  classifier. Splits input data into training and test sets. The training set\r\n",
      "  is used to train and test the estimator using a stratified k-fold cross-\r\n",
      "  validation scheme. This includes optional steps for automated feature\r\n",
      "  extraction and hyperparameter optimization. The test set validates\r\n",
      "  classification accuracy of the optimized estimator. Outputs classification\r\n",
      "  results for test set. For more details on the learning algorithm, see\r\n",
      "  http://scikit-learn.org/stable/supervised_learning.html\r\n",
      "\r\n",
      "\u001b[1mInputs\u001b[0m:\r\n",
      "  \u001b[94m\u001b[4m--i-table\u001b[0m ARTIFACT \u001b[32mFeatureTable[Frequency]\u001b[0m\r\n",
      "                       Feature table containing all features that should be\r\n",
      "                       used for target prediction.                  \u001b[35m[required]\u001b[0m\r\n",
      "\u001b[1mParameters\u001b[0m:\r\n",
      "  \u001b[94m\u001b[4m--m-metadata-file\u001b[0m METADATA\r\n",
      "  \u001b[94m\u001b[4m--m-metadata-column\u001b[0m COLUMN  \u001b[32mMetadataColumn[Categorical]\u001b[0m\r\n",
      "                       Categorical metadata column to use as prediction\r\n",
      "                       target.                                      \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m--p-test-size\u001b[0m PROPORTION\r\n",
      "    \u001b[32mRange(0.0, 1.0)\u001b[0m    Fraction of input samples to exclude from training set\r\n",
      "                       and use for classifier testing.          \u001b[35m[default: 0.2]\u001b[0m\r\n",
      "  \u001b[94m--p-step\u001b[0m PROPORTION \u001b[32mRange(0.0, 1.0, inclusive_start=False)\u001b[0m\r\n",
      "                       If \u001b[4moptimize-feature-selection\u001b[0m is True, step is the\r\n",
      "                       percentage of features to remove at each iteration.\r\n",
      "                                                               \u001b[35m[default: 0.05]\u001b[0m\r\n",
      "  \u001b[94m--p-cv\u001b[0m INTEGER       Number of k-fold cross-validations to perform.\r\n",
      "    \u001b[32mRange(1, None)\u001b[0m                                                \u001b[35m[default: 5]\u001b[0m\r\n",
      "  \u001b[94m--p-random-state\u001b[0m INTEGER\r\n",
      "                       Seed used by random number generator.        \u001b[35m[optional]\u001b[0m\r\n",
      "  \u001b[94m--p-n-jobs\u001b[0m INTEGER   Number of jobs to run in parallel.         \u001b[35m[default: 1]\u001b[0m\r\n",
      "  \u001b[94m--p-n-estimators\u001b[0m INTEGER\r\n",
      "    \u001b[32mRange(1, None)\u001b[0m     Number of trees to grow for estimation. More trees\r\n",
      "                       will improve predictive accuracy up to a threshold\r\n",
      "                       level, but will also increase time and memory\r\n",
      "                       requirements. This parameter only affects ensemble\r\n",
      "                       estimators, such as Random Forest, AdaBoost,\r\n",
      "                       ExtraTrees, and GradientBoosting.        \u001b[35m[default: 100]\u001b[0m\r\n",
      "  \u001b[94m--p-estimator\u001b[0m TEXT \u001b[32mChoices('RandomForestClassifier',\u001b[0m\r\n",
      "    \u001b[32m'ExtraTreesClassifier', 'GradientBoostingClassifier',\u001b[0m\r\n",
      "    \u001b[32m'AdaBoostClassifier', 'KNeighborsClassifier', 'LinearSVC', 'SVC')\u001b[0m\r\n",
      "                       Estimator method to use for sample prediction.\r\n",
      "                                           \u001b[35m[default: 'RandomForestClassifier']\u001b[0m\r\n",
      "  \u001b[94m--p-optimize-feature-selection\u001b[0m / \u001b[94m--p-no-optimize-feature-selection\u001b[0m\r\n",
      "                       Automatically optimize input feature selection using\r\n",
      "                       recursive feature elimination.         \u001b[35m[default: False]\u001b[0m\r\n",
      "  \u001b[94m--p-parameter-tuning\u001b[0m / \u001b[94m--p-no-parameter-tuning\u001b[0m\r\n",
      "                       Automatically tune hyperparameters using random grid\r\n",
      "                       search.                                \u001b[35m[default: False]\u001b[0m\r\n",
      "  \u001b[94m--p-palette\u001b[0m TEXT \u001b[32mChoices('YellowOrangeBrown', 'YellowOrangeRed',\u001b[0m\r\n",
      "    \u001b[32m'OrangeRed', 'PurpleRed', 'RedPurple', 'BluePurple', 'GreenBlue',\u001b[0m\r\n",
      "    \u001b[32m'PurpleBlue', 'YellowGreen', 'summer', 'copper', 'viridis', 'cividis',\u001b[0m\r\n",
      "    \u001b[32m'plasma', 'inferno', 'magma', 'sirocco', 'drifting', 'melancholy',\u001b[0m\r\n",
      "    \u001b[32m'enigma', 'eros', 'spectre', 'ambition', 'mysteriousstains', 'daydream',\u001b[0m\r\n",
      "    \u001b[32m'solano', 'navarro', 'dandelions', 'deepblue', 'verve', 'greyscale')\u001b[0m\r\n",
      "                       The color palette to use for plotting.\r\n",
      "                                                          \u001b[35m[default: 'sirocco']\u001b[0m\r\n",
      "  \u001b[94m--p-missing-samples\u001b[0m TEXT \u001b[32mChoices('error', 'ignore')\u001b[0m\r\n",
      "                       How to handle missing samples in metadata. \"error\"\r\n",
      "                       will fail if missing samples are detected. \"ignore\"\r\n",
      "                       will cause the feature table and metadata to be\r\n",
      "                       filtered, so that only samples found in both files are\r\n",
      "                       retained.                            \u001b[35m[default: 'error']\u001b[0m\r\n",
      "\u001b[1mOutputs\u001b[0m:\r\n",
      "  \u001b[94m\u001b[4m--o-sample-estimator\u001b[0m ARTIFACT \u001b[32mSampleEstimator[Classifier]\u001b[0m\r\n",
      "                       Trained sample estimator.                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-feature-importance\u001b[0m ARTIFACT \u001b[32mFeatureData[Importance]\u001b[0m\r\n",
      "                       Importance of each input feature to model accuracy.\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-predictions\u001b[0m ARTIFACT \u001b[32mSampleData[ClassifierPredictions]\u001b[0m\r\n",
      "                       Predicted target values for each input sample.\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-model-summary\u001b[0m VISUALIZATION\r\n",
      "                       Summarized parameter and (if enabled) feature\r\n",
      "                       selection information for the trained estimator.\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-accuracy-results\u001b[0m VISUALIZATION\r\n",
      "                       Accuracy results visualization.              \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-probabilities\u001b[0m ARTIFACT \u001b[32mSampleData[Probabilities]\u001b[0m\r\n",
      "                       Predicted class probabilities for each input sample.\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-heatmap\u001b[0m VISUALIZATION\r\n",
      "                       A heatmap of the top 50 most important features from\r\n",
      "                       the table.                                   \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-training-targets\u001b[0m ARTIFACT \u001b[32mSampleData[TrueTargets]\u001b[0m\r\n",
      "                       Series containing true target values of train samples\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "  \u001b[94m\u001b[4m--o-test-targets\u001b[0m ARTIFACT \u001b[32mSampleData[TrueTargets]\u001b[0m\r\n",
      "                       Series containing true target values of test samples\r\n",
      "                                                                    \u001b[35m[required]\u001b[0m\r\n",
      "\u001b[1mMiscellaneous\u001b[0m:\r\n",
      "  \u001b[94m--output-dir\u001b[0m PATH    Output unspecified results to a directory\r\n",
      "  \u001b[94m--verbose\u001b[0m / \u001b[94m--quiet\u001b[0m  Display verbose output to stdout and/or stderr during\r\n",
      "                       execution of this action. Or silence output if\r\n",
      "                       execution is successful (silence is golden).\r\n",
      "  \u001b[94m--example-data\u001b[0m PATH  Write example data and exit.\r\n",
      "  \u001b[94m--citations\u001b[0m          Show citations and exit.\r\n",
      "  \u001b[94m--help\u001b[0m               Show this message and exit.\r\n",
      "\r\n",
      "\u001b[33m                  There were some problems with the command:                  \u001b[0m\r\n",
      "\u001b[31m\u001b[1m (1/10) Invalid value for '--output-dir': '../data/classifier-data' already\r\n",
      "  exists, will not overwrite.\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (2/10) Missing option '--o-sample-estimator'. (\"--output-dir\" may also be\r\n",
      "  used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (3/10) Missing option '--o-feature-importance'. (\"--output-dir\" may also be\r\n",
      "  used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (4/10) Missing option '--o-predictions'. (\"--output-dir\" may also be used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (5/10) Missing option '--o-model-summary'. (\"--output-dir\" may also be used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (6/10) Missing option '--o-accuracy-results'. (\"--output-dir\" may also be\r\n",
      "  used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (7/10) Missing option '--o-probabilities'. (\"--output-dir\" may also be used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (8/10) Missing option '--o-heatmap'. (\"--output-dir\" may also be used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (9/10) Missing option '--o-training-targets'. (\"--output-dir\" may also be\r\n",
      "  used)\u001b[0m\r\n",
      "\u001b[31m\u001b[1m (10/10) Missing option '--o-test-targets'. (\"--output-dir\" may also be used)\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime sample-classifier classify-samples \\\n",
    "  --i-table ../data/qiime_table.qza \\\n",
    "  --m-metadata-file ../data/metadata.tsv \\\n",
    "  --m-metadata-column ATTRIBUTE_Sample_Area \\\n",
    "  --p-optimize-feature-selection \\\n",
    "  --p-parameter-tuning \\\n",
    "  --p-estimator RandomForestClassifier \\\n",
    "  --p-n-estimators 500 \\\n",
    "  --p-random-state 123 \\\n",
    "  --output-dir ../data/classifier-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><img onload=\"(function(div, url){\n",
       "if (typeof require !== 'undefined') {\n",
       "    var baseURL = require.toUrl('').split('/').slice(0, -2).join('/');\n",
       "} else {\n",
       "    var baseURL = JSON.parse(\n",
       "        document.getElementById('jupyter-config-data').innerHTML\n",
       "    ).baseUrl.slice(0, -1);\n",
       "}\n",
       "url = baseURL + url;\n",
       "fetch(url).then(function(res) {\n",
       "    if (res.status === 404) {\n",
       "        div.innerHTML = 'Install QIIME 2 Jupyter extension with:<br />' +\n",
       "                        '<code>jupyter serverextension enable --py qiime2' +\n",
       "                        ' --sys-prefix</code><br />then restart your server.' +\n",
       "                        '<br /><br />(Interactive output not available on ' +\n",
       "                        'static notebook viewer services like nbviewer.)';\n",
       "    } else if (res.status === 409) {\n",
       "        div.innerHTML = 'Visualization no longer in scope. Re-run this cell' +\n",
       "                        ' to see the visualization.';\n",
       "    } else if (res.ok) {\n",
       "        url = res.url;\n",
       "        div.innerHTML = '<iframe src=\\'' + url + '\\' style=\\'' +\n",
       "                        'width: 100%; height: 700px; border: 0;\\'>' +\n",
       "                        '</iframe><hr />Open in a: <a href=\\'' + url + '\\'' +\n",
       "                        ' target=\\'_blank\\'>new window</a>'\n",
       "    } else {\n",
       "        div.innerHTML = 'Something has gone wrong. Check notebook server for' +\n",
       "                        ' errors.';\n",
       "    }\n",
       "});\n",
       "})(this.parentElement, '/qiime2/redirect?location=/tmp/qiime2/root/data/ea6da677-2e4d-4df6-bd77-05d8dedc88bd')\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" /></div>"
      ],
      "text/plain": [
       "<visualization: Visualization uuid: ea6da677-2e4d-4df6-bd77-05d8dedc88bd>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Visualization.load('../data/classifier-data/heatmap.qzv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \u001b[94mqiime diversity beta-group-significance\u001b[0m [OPTIONS]\n",
      "\n",
      "  Determine whether groups of samples are significantly different from one\n",
      "  another using a permutation-based statistical test.\n",
      "\n",
      "\u001b[1mInputs\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--i-distance-matrix\u001b[0m ARTIFACT\n",
      "    \u001b[32mDistanceMatrix\u001b[0m     Matrix of distances between pairs of samples.\n",
      "                                                                    \u001b[35m[required]\u001b[0m\n",
      "\u001b[1mParameters\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--m-metadata-file\u001b[0m METADATA\n",
      "  \u001b[94m\u001b[4m--m-metadata-column\u001b[0m COLUMN  \u001b[32mMetadataColumn[Categorical]\u001b[0m\n",
      "                       Categorical sample metadata column.          \u001b[35m[required]\u001b[0m\n",
      "  \u001b[94m--p-method\u001b[0m TEXT \u001b[32mChoices('permanova', 'anosim', 'permdisp')\u001b[0m\n",
      "                       The group significance test to be applied.\n",
      "                                                        \u001b[35m[default: 'permanova']\u001b[0m\n",
      "  \u001b[94m--p-pairwise\u001b[0m / \u001b[94m--p-no-pairwise\u001b[0m\n",
      "                       Perform pairwise tests between all pairs of groups in\n",
      "                       addition to the test across all groups. This can be\n",
      "                       very slow if there are a lot of groups in the metadata\n",
      "                       column.                                \u001b[35m[default: False]\u001b[0m\n",
      "  \u001b[94m--p-permutations\u001b[0m INTEGER\n",
      "                       The number of permutations to be run when computing\n",
      "                       p-values.                                \u001b[35m[default: 999]\u001b[0m\n",
      "\u001b[1mOutputs\u001b[0m:\n",
      "  \u001b[94m\u001b[4m--o-visualization\u001b[0m VISUALIZATION\n",
      "                                                                    \u001b[35m[required]\u001b[0m\n",
      "\u001b[1mMiscellaneous\u001b[0m:\n",
      "  \u001b[94m--output-dir\u001b[0m PATH    Output unspecified results to a directory\n",
      "  \u001b[94m--verbose\u001b[0m / \u001b[94m--quiet\u001b[0m  Display verbose output to stdout and/or stderr during\n",
      "                       execution of this action. Or silence output if\n",
      "                       execution is successful (silence is golden).\n",
      "  \u001b[94m--example-data\u001b[0m PATH  Write example data and exit.\n",
      "  \u001b[94m--citations\u001b[0m          Show citations and exit.\n",
      "  \u001b[94m--help\u001b[0m               Show this message and exit.\n",
      "\n",
      "\u001b[33m                    There was a problem with the command:                     \u001b[0m\n",
      "\u001b[31m\u001b[1m (1/1) Invalid value for '--o-visualization': Directory '../data/classifier-\n",
      "  data' does not exist, cannot save 'permanova.qzv' into it.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! qiime diversity beta-group-significance \\\n",
    "  --i-distance-matrix ../data/distance_matrix.qza \\\n",
    "  --m-metadata-file ../data/metadata.tsv \\\n",
    "  --m-metadata-column ATTRIBUTE_Sample_Area \\\n",
    "  --o-visualization ../data/classifier-data/permanova.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Archive does not contain a correctly formatted VERSION file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:118\u001b[0m, in \u001b[0;36m_Archive._get_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mVERSION_FILE) \u001b[39mas\u001b[39;00m fh:\n\u001b[1;32m    119\u001b[0m         header, version_line, framework_version_line, eof \u001b[39m=\u001b[39m \\\n\u001b[1;32m    120\u001b[0m             fh\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:248\u001b[0m, in \u001b[0;36m_NoOpArchive.open\u001b[0;34m(self, relpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, relpath):\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, relpath))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/classifier-data/permanova.qzv/VERSION'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Visualization\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m../data/classifier-data/permanova.qzv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/sdk/result.py:74\u001b[0m, in \u001b[0;36mResult.load\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m# Check if the data is already in the cache (if the uuid is in\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# cache.data) and load it from the cache if it is. Avoids unzipping the\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m# qza again if we already have it.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m cache \u001b[39m=\u001b[39m get_cache()\n\u001b[0;32m---> 74\u001b[0m peek \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mpeek(filepath)\n\u001b[1;32m     75\u001b[0m archiver \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39m_load_uuid(peek\u001b[39m.\u001b[39muuid)\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m archiver:\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/sdk/result.py:58\u001b[0m, in \u001b[0;36mResult.peek\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpeek\u001b[39m(\u001b[39mcls\u001b[39m, filepath):\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m ResultMetadata(\u001b[39m*\u001b[39marchive\u001b[39m.\u001b[39;49mArchiver\u001b[39m.\u001b[39;49mpeek(filepath))\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:335\u001b[0m, in \u001b[0;36mArchiver.peek\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpeek\u001b[39m(\u001b[39mcls\u001b[39m, filepath):\n\u001b[0;32m--> 335\u001b[0m     archive \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_archive(filepath)\n\u001b[1;32m    336\u001b[0m     Format \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_format_class(archive\u001b[39m.\u001b[39mversion)\n\u001b[1;32m    337\u001b[0m     \u001b[39mif\u001b[39;00m Format \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:319\u001b[0m, in \u001b[0;36mArchiver.get_archive\u001b[0;34m(cls, filepath)\u001b[0m\n\u001b[1;32m    317\u001b[0m     archive \u001b[39m=\u001b[39m _ZipArchive(filepath)\n\u001b[1;32m    318\u001b[0m \u001b[39melif\u001b[39;00m _NoOpArchive\u001b[39m.\u001b[39mis_archive_type(filepath):\n\u001b[0;32m--> 319\u001b[0m     archive \u001b[39m=\u001b[39m _NoOpArchive(filepath)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not a QIIME archive.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filepath)\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:92\u001b[0m, in \u001b[0;36m_Archive.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m path\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muuid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_uuid()\n\u001b[0;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework_version \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_versions()\n",
      "File \u001b[0;32m~/anaconda3/envs/qiime2/lib/python3.8/site-packages/qiime2/core/archive/archiver.py:128\u001b[0m, in \u001b[0;36m_Archive._get_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m version, framework_version\n\u001b[1;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# TODO: make a \"better\" parser which isn't just a catch-all\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArchive does not contain a correctly formatted\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m VERSION file.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Archive does not contain a correctly formatted VERSION file."
     ]
    }
   ],
   "source": [
    "Visualization.load(\"../data/classifier-data/permanova.qzv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
